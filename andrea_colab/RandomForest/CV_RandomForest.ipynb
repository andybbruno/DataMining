{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_RandomForest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk5r6xAHkMuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "trainCSV = \"https://raw.githubusercontent.com/andybbruno/DataMining/master/new_train_cleaned.csv?token=AGWKQXZRZZDVJOUEMOQ3PJC6AHO6U\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQpk6xIlkTAh",
        "colab_type": "code",
        "outputId": "9dd3a62a-3f3d-4e92-8c4a-68b75e3e581a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# READ AND DROP COLUMNS\n",
        "df = pd.read_csv(trainCSV)\n",
        "y = df['IsBadBuy']\n",
        "X = df.drop(columns=['IsBadBuy'])\n",
        "\n",
        "# Split the dataset in two equal parts\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
        "\n",
        "# Set the parameters by cross-validation\n",
        "tuned_parameters = {\n",
        "    'n_estimators': [25, 50, 100, 200, 500, 1000]\n",
        "}\n",
        "\n",
        "#scores = ['precision', 'recall', 'f1']\n",
        "scores = ['recall', 'f1']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for ----> %s\" % score)\n",
        "    print()\n",
        "    \n",
        "    obj = RandomForestClassifier()\n",
        "    \n",
        "    if (score == \"recall\"):\n",
        "      clf = GridSearchCV(obj, tuned_parameters, cv=5, scoring=score)\n",
        "    else:\n",
        "      clf = GridSearchCV(obj, tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for ----> recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'n_estimators': 1000}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.246 (+/-0.036) for {'n_estimators': 25}\n",
            "0.245 (+/-0.036) for {'n_estimators': 50}\n",
            "0.246 (+/-0.037) for {'n_estimators': 100}\n",
            "0.248 (+/-0.033) for {'n_estimators': 200}\n",
            "0.250 (+/-0.033) for {'n_estimators': 500}\n",
            "0.250 (+/-0.037) for {'n_estimators': 1000}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.95     20507\n",
            "           1       0.83      0.24      0.37      2847\n",
            "\n",
            "    accuracy                           0.90     23354\n",
            "   macro avg       0.87      0.62      0.66     23354\n",
            "weighted avg       0.90      0.90      0.88     23354\n",
            "\n",
            "\n",
            "# Tuning hyper-parameters for ----> f1\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'n_estimators': 1000}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.661 (+/-0.025) for {'n_estimators': 25}\n",
            "0.661 (+/-0.020) for {'n_estimators': 50}\n",
            "0.663 (+/-0.024) for {'n_estimators': 100}\n",
            "0.664 (+/-0.022) for {'n_estimators': 200}\n",
            "0.664 (+/-0.023) for {'n_estimators': 500}\n",
            "0.664 (+/-0.023) for {'n_estimators': 1000}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.95     20507\n",
            "           1       0.83      0.24      0.37      2847\n",
            "\n",
            "    accuracy                           0.90     23354\n",
            "   macro avg       0.87      0.61      0.66     23354\n",
            "weighted avg       0.89      0.90      0.88     23354\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}