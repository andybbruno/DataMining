{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_UnderSampling_AdaBoost.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ865JgUmI6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "83a3df19-4f60-4e3f-a3ae-0c9df5cd46dd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from imblearn.pipeline import Pipeline, make_pipeline\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "trainCSV = \"https://raw.githubusercontent.com/andybbruno/DataMining/master/new_train_cleaned.csv?token=AGWKQX6PGJXV4U2SBDZHALC6BY3P4\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmjk1Wnln_RO",
        "colab_type": "code",
        "outputId": "61848b86-86ac-4624-9fc6-012da0bcdffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# READ AND DROP COLUMNS\n",
        "df = pd.read_csv(trainCSV)\n",
        "df.drop(df.columns[0], axis=1, inplace=True)\n",
        "y = df['IsBadBuy']\n",
        "X = df.drop(columns=['IsBadBuy'])\n",
        "\n",
        "# Split the dataset in two equal parts\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
        "\n",
        "# Set the parameters by cross-validation\n",
        "params = {\n",
        "    'n_estimators': [5, 10, 25, 50, 100],\n",
        "    'learning_rate' : [0.1, 0.25, 0.5, 0.75, 1],\n",
        " }\n",
        "\n",
        "new_params = {'adaboostclassifier__' + key: params[key] for key in params}\n",
        "\n",
        "#scores = ['precision', 'recall', 'f1']\n",
        "scores = ['recall', 'f1']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for ----> %s\" % score)\n",
        "    print()\n",
        "    \n",
        "    obj = make_pipeline(RandomUnderSampler(), AdaBoostClassifier())\n",
        "    \n",
        "    if (score == \"recall\"):\n",
        "      clf = GridSearchCV(obj, param_grid=new_params, cv=5, scoring=score)\n",
        "    else:\n",
        "      clf = GridSearchCV(obj, param_grid=new_params, cv=5, scoring='%s_macro' % score)\n",
        "                         \n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-86e08ea96a43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainCSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IsBadBuy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IsBadBuy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for ----> recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 25}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.258 (+/-0.033) for {'adaboostclassifier__learning_rate': 0.1, 'adaboostclassifier__n_estimators': 5}\n",
            "0.258 (+/-0.033) for {'adaboostclassifier__learning_rate': 0.1, 'adaboostclassifier__n_estimators': 10}\n",
            "0.441 (+/-0.050) for {'adaboostclassifier__learning_rate': 0.1, 'adaboostclassifier__n_estimators': 25}\n",
            "0.502 (+/-0.055) for {'adaboostclassifier__learning_rate': 0.1, 'adaboostclassifier__n_estimators': 50}\n",
            "0.535 (+/-0.054) for {'adaboostclassifier__learning_rate': 0.1, 'adaboostclassifier__n_estimators': 100}\n",
            "0.330 (+/-0.219) for {'adaboostclassifier__learning_rate': 0.25, 'adaboostclassifier__n_estimators': 5}\n",
            "0.473 (+/-0.091) for {'adaboostclassifier__learning_rate': 0.25, 'adaboostclassifier__n_estimators': 10}\n",
            "0.533 (+/-0.036) for {'adaboostclassifier__learning_rate': 0.25, 'adaboostclassifier__n_estimators': 25}\n",
            "0.549 (+/-0.039) for {'adaboostclassifier__learning_rate': 0.25, 'adaboostclassifier__n_estimators': 50}\n",
            "0.567 (+/-0.038) for {'adaboostclassifier__learning_rate': 0.25, 'adaboostclassifier__n_estimators': 100}\n",
            "0.446 (+/-0.034) for {'adaboostclassifier__learning_rate': 0.5, 'adaboostclassifier__n_estimators': 5}\n",
            "0.525 (+/-0.081) for {'adaboostclassifier__learning_rate': 0.5, 'adaboostclassifier__n_estimators': 10}\n",
            "0.571 (+/-0.031) for {'adaboostclassifier__learning_rate': 0.5, 'adaboostclassifier__n_estimators': 25}\n",
            "0.571 (+/-0.071) for {'adaboostclassifier__learning_rate': 0.5, 'adaboostclassifier__n_estimators': 50}\n",
            "0.587 (+/-0.057) for {'adaboostclassifier__learning_rate': 0.5, 'adaboostclassifier__n_estimators': 100}\n",
            "0.480 (+/-0.105) for {'adaboostclassifier__learning_rate': 0.75, 'adaboostclassifier__n_estimators': 5}\n",
            "0.568 (+/-0.062) for {'adaboostclassifier__learning_rate': 0.75, 'adaboostclassifier__n_estimators': 10}\n",
            "0.589 (+/-0.041) for {'adaboostclassifier__learning_rate': 0.75, 'adaboostclassifier__n_estimators': 25}\n",
            "0.589 (+/-0.039) for {'adaboostclassifier__learning_rate': 0.75, 'adaboostclassifier__n_estimators': 50}\n",
            "0.598 (+/-0.049) for {'adaboostclassifier__learning_rate': 0.75, 'adaboostclassifier__n_estimators': 100}\n",
            "0.500 (+/-0.135) for {'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 5}\n",
            "0.561 (+/-0.086) for {'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 10}\n",
            "0.600 (+/-0.044) for {'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 25}\n",
            "0.594 (+/-0.025) for {'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 50}\n",
            "0.594 (+/-0.035) for {'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 100}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.83     20507\n",
            "           1       0.25      0.57      0.34      2847\n",
            "\n",
            "    accuracy                           0.73     23354\n",
            "   macro avg       0.59      0.67      0.59     23354\n",
            "weighted avg       0.84      0.73      0.77     23354\n",
            "\n",
            "\n",
            "# Tuning hyper-parameters for ----> f1\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'adaboostclassifier__learning_rate': 0.1, 'adaboostclassifier__n_estimators': 5}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.660 (+/-0.019) for {'adaboostclassifier__learning_rate': 0.1, 'adaboostclassifier__n_estimators': 5}\n",
            "0.660 (+/-0.019) for {'adaboostclassifier__learning_rate': 0.1, 'adaboostclassifier__n_estimators': 10}\n",
            "0.640 (+/-0.023) for {'adaboostclassifier__learning_rate': 0.1, 'adaboostclassifier__n_estimators': 25}\n",
            "0.620 (+/-0.018) for {'adaboostclassifier__learning_rate': 0.1, 'adaboostclassifier__n_estimators': 50}\n",
            "0.621 (+/-0.010) for {'adaboostclassifier__learning_rate': 0.1, 'adaboostclassifier__n_estimators': 100}\n",
            "0.647 (+/-0.055) for {'adaboostclassifier__learning_rate': 0.25, 'adaboostclassifier__n_estimators': 5}\n",
            "0.634 (+/-0.018) for {'adaboostclassifier__learning_rate': 0.25, 'adaboostclassifier__n_estimators': 10}\n",
            "0.619 (+/-0.005) for {'adaboostclassifier__learning_rate': 0.25, 'adaboostclassifier__n_estimators': 25}\n",
            "0.614 (+/-0.009) for {'adaboostclassifier__learning_rate': 0.25, 'adaboostclassifier__n_estimators': 50}\n",
            "0.613 (+/-0.009) for {'adaboostclassifier__learning_rate': 0.25, 'adaboostclassifier__n_estimators': 100}\n",
            "0.626 (+/-0.025) for {'adaboostclassifier__learning_rate': 0.5, 'adaboostclassifier__n_estimators': 5}\n",
            "0.614 (+/-0.018) for {'adaboostclassifier__learning_rate': 0.5, 'adaboostclassifier__n_estimators': 10}\n",
            "0.607 (+/-0.011) for {'adaboostclassifier__learning_rate': 0.5, 'adaboostclassifier__n_estimators': 25}\n",
            "0.608 (+/-0.010) for {'adaboostclassifier__learning_rate': 0.5, 'adaboostclassifier__n_estimators': 50}\n",
            "0.602 (+/-0.010) for {'adaboostclassifier__learning_rate': 0.5, 'adaboostclassifier__n_estimators': 100}\n",
            "0.621 (+/-0.022) for {'adaboostclassifier__learning_rate': 0.75, 'adaboostclassifier__n_estimators': 5}\n",
            "0.597 (+/-0.014) for {'adaboostclassifier__learning_rate': 0.75, 'adaboostclassifier__n_estimators': 10}\n",
            "0.596 (+/-0.017) for {'adaboostclassifier__learning_rate': 0.75, 'adaboostclassifier__n_estimators': 25}\n",
            "0.593 (+/-0.009) for {'adaboostclassifier__learning_rate': 0.75, 'adaboostclassifier__n_estimators': 50}\n",
            "0.594 (+/-0.007) for {'adaboostclassifier__learning_rate': 0.75, 'adaboostclassifier__n_estimators': 100}\n",
            "0.587 (+/-0.043) for {'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 5}\n",
            "0.591 (+/-0.026) for {'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 10}\n",
            "0.592 (+/-0.020) for {'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 25}\n",
            "0.591 (+/-0.010) for {'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 50}\n",
            "0.588 (+/-0.009) for {'adaboostclassifier__learning_rate': 1, 'adaboostclassifier__n_estimators': 100}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94     20507\n",
            "           1       0.71      0.25      0.37      2847\n",
            "\n",
            "    accuracy                           0.90     23354\n",
            "   macro avg       0.81      0.62      0.65     23354\n",
            "weighted avg       0.88      0.90      0.87     23354\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}